{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPH77RByrg5jaST3giHekol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdh93621/Deep-learning/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW3jJm-oLdjp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv4FbmmaLf7D"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyC4bUmJLiKe"
      },
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+ \"/spa-eng/spa.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbEPObLtLj6t",
        "outputId": "7808b0d5-79d7-4038-a242-7e528c53717d"
      },
      "source": [
        "with open(path_to_file, \"r\") as f:\n",
        "  raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size: \", len(raw))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Size:  118964\n",
            "Example:\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l_t-G-JLsPE"
      },
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Eo-pWWWLus7",
        "outputId": "42b2549b-11ee-443c-f193-206b6a48d4df"
      },
      "source": [
        "eng_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "  eng, spa = pair.split(\"\\t\")\n",
        "\n",
        "  eng_corpus.append(preprocess_sentence(eng))\n",
        "  dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English :\", eng_corpus[100])\n",
        "print(\"Spanish :\", dec_corpus[100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English : go away !\n",
            "Spanish : <start> salga de aqu ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PjC3PFrLwU9"
      },
      "source": [
        "def tokenize(corpus):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbpDNomSLyEb"
      },
      "source": [
        "# 토큰화 하기\n",
        "# 훈련데이터와 검증데이터로 분리하기\n",
        "# 정제된 텍스트를 아래 tokenize()함수를 사용해 토큰화해서 텐서로 변환하세요~\n",
        "enc_tensor, enc_tokenizer = tokenize(eng_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQPNTPzALz56"
      },
      "source": [
        "# 그리고 변환된 텐서를 80%의 훈련데이터와 20% 검증데이터로 분리하세요\n",
        "# 단 Tokenizer의 단어수는 자유롭게 진행하세요!\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size = 0.2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOGVSaUbL2f7",
        "outputId": "f0076f4a-f506-406b-8265-7a5bb792d656"
      },
      "source": [
        "# english vocab size반환\n",
        "# spanish vocab size반환\n",
        "print('English Vocab Size :',len(enc_tokenizer.index_word))\n",
        "print('Spanish Vocab Size :',len(dec_tokenizer.index_word))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab Size : 4931\n",
            "Spanish Vocab Size : 8893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSfjdAwNL4HU"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w_dec = tf.keras.layers.Dense(units)\n",
        "    self.w_enc = tf.keras.layers.Dense(units)\n",
        "    self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, h_enc, h_dec):\n",
        "    # h_enc shape : [batch x length x units]\n",
        "    # h_dec shape : [batch x units]\n",
        "\n",
        "    h_enc = self.w_enc(h_enc)\n",
        "    h_dec = tf.expand_dims(h_dec, 1)\n",
        "    h_dec = self.w_dec(h_dec)\n",
        "\n",
        "    score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "    attn = tf.nn.softmax(score, axis =1)\n",
        "\n",
        "    context_vec = attn * h_enc\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "    return context_vec, attn"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BexRpdbpL6dq"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    # todo\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    # todo \n",
        "    out = self.embedding(x)\n",
        "    out = self.gru(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsy2D8XtMBXE"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    ## Todo\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, h_dec, enc_out):\n",
        "    ## Todo\n",
        "    context_vec, attn = self.attention(enc_out, h_dec)\n",
        "    \n",
        "    out = self.embedding(x)\n",
        "    out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "\n",
        "    out, h_dec = self.gru(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[2]))\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, h_dec, attn"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tshs9Y42MDCe",
        "outputId": "33c416f9-b54b-4714-8975-443aa2d498f8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "src_vocab_size = len(enc_tokenizer.index_word) + 1\n",
        "tgt_vocab_size = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(src_vocab_size, embedding_dim, units)\n",
        "decoder = Decoder(tgt_vocab_size, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_state, sample_output)\n",
        "\n",
        "print('Decoder output :', sample_logits.shape)\n",
        "print('Decoder Hidden State :', h_dec.shape)\n",
        "print('Attention :', attn.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder output : (64, 8894)\n",
            "Decoder Hidden State : (64, 1024)\n",
            "Attention : (64, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfPpwJKXMF9Q"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "# Categorical Crossentropy()\n",
        "# [0.1, 0.2, 0.7] --> onehot encoding [0, 0, 1]\n",
        "# SparseCategoricalCrossentropy()\n",
        "# [0.1, 0.2, 0.7] ---> 정수 인덱스 2\n",
        "# True --> 모델의 출력값을 그대로 전달\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss)  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y6SypWoMzRF"
      },
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_out = encoder(src)\n",
        "    h_dec = enc_out[:, -1]\n",
        "\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "      pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "      loss += loss_function(tgt[:, t], pred)\n",
        "      dec_src = tf.expand_dims(tgt[:,t], 1)\n",
        "\n",
        "  batch_loss = (loss/int(tgt.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBJuFkEJOGvM"
      },
      "source": [
        "train_step 학습 과정\n",
        "1. Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out 생성\n",
        "2. Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
        "3. t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의. h_dec = enc_out[:,-1]\n",
        "4. 문장과 enc_out, Hidden State를 기반으로 다음단어(t=1)예측, pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JACAR7qHOFMc",
        "outputId": "00ab361c-ca61-444a-9681-fe3aafb5bd66"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                            dec_train[idx:idx+BATCH_SIZE],\n",
        "                            encoder,\n",
        "                            decoder,\n",
        "                            optimizer,\n",
        "                            dec_tokenizer)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    t.set_description_str('Epoch %2d' % (epoch+1))\n",
        "    t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch+1)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [01:21<00:00,  4.60it/s, Loss 1.3393]\n",
            "Epoch  2: 100%|██████████| 375/375 [01:02<00:00,  6.04it/s, Loss 0.8775]\n",
            "Epoch  3: 100%|██████████| 375/375 [01:01<00:00,  6.06it/s, Loss 0.6195]\n",
            "Epoch  4: 100%|██████████| 375/375 [01:02<00:00,  6.04it/s, Loss 0.4420]\n",
            "Epoch  5: 100%|██████████| 375/375 [01:01<00:00,  6.05it/s, Loss 0.3321]\n",
            "Epoch  6: 100%|██████████| 375/375 [01:01<00:00,  6.06it/s, Loss 0.2559]\n",
            "Epoch  7: 100%|██████████| 375/375 [01:02<00:00,  6.05it/s, Loss 0.2094]\n",
            "Epoch  8: 100%|██████████| 375/375 [01:01<00:00,  6.06it/s, Loss 0.1771]\n",
            "Epoch  9: 100%|██████████| 375/375 [01:01<00:00,  6.05it/s, Loss 0.1554]\n",
            "Epoch 10: 100%|██████████| 375/375 [01:02<00:00,  6.05it/s, Loss 0.1421]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_IokSFSk6O"
      },
      "source": [
        "### Evaluation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ZjIsbPLaTAPl",
        "outputId": "c4c9c53d-9b2f-47b9-91ed-dc428034b1bf"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(dec_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "\n",
        "translate(\"Can I have some coffee?\", encoder, decoder)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: can i have some coffee ?\n",
            "Predicted translation: me dan algo de caf ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLVwswYDTqyf"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}