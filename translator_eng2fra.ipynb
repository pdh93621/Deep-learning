{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translator_eng2fra.ipynb",
      "provenance": [],
      "mount_file_id": "1WgDRBmQRR7XWP4FV-Ohv7lpwcyHP1_AN",
      "authorship_tag": "ABX9TyM4tYoBJezEtzyZiAd50tSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdh93621/Deep-learning/blob/main/translator_eng2fra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlKbDHW_X_Ht"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od2j4JaYYHp2",
        "outputId": "286ef992-6076-466e-fb24-f7b0eb978fe9"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('11-0.txt', <http.client.HTTPMessage at 0x7f2e8a2b5390>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzb0UbxUYKIL"
      },
      "source": [
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "  line = line.strip()\n",
        "  line = line.lower()\n",
        "  line = line.decode('ascii', 'ignore')\n",
        "  if len(line) > 0:\n",
        "    lines.append(line)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhxUmwtEYcC0",
        "outputId": "2ce4758e-106b-4422-9c01-59ca78706a3b"
      },
      "source": [
        "lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80R5s7IAYmqa",
        "outputId": "2941e74c-ea73-4c67-f5a6-00f24e12808a"
      },
      "source": [
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 갯수: %d' %len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 갯수: 159484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJAyAxZCY5uw",
        "outputId": "f0f5f330-1cb6-4edc-a952-3c6f7ca014a8"
      },
      "source": [
        "print(text[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the projec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWEPHWdtY-nF",
        "outputId": "58ee27c0-3bd4-4103-c0c7-a2398c71613e"
      },
      "source": [
        "#글자 집합\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f'글자 집합의 크기: {vocab_size}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIhBii_7ZYoO",
        "outputId": "a62bf49d-202d-4d61-b571-c8004c8f7934"
      },
      "source": [
        "print(char_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl9UQco4ZaKP",
        "outputId": "a0e74e60-46af-4bf8-f378-c1cd77119852"
      },
      "source": [
        "# 글자 집합에 인데스를 부여하고 전부 출력하기\n",
        "char_to_index = dict((c,i) for i,c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKE18htZ2c_"
      },
      "source": [
        "# 인덱스로부터 글자를 리턴하기\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9uyzlyNaOAl",
        "outputId": "44b8cf84-bd08-4d24-c915-2c758f52c24b"
      },
      "source": [
        "print(index_to_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOsDA-AxaQBo"
      },
      "source": [
        "# 훈련데이터를 구성\n",
        "# apple\n",
        "# sample의 길이 4\n",
        "\n",
        "# example) 샘플의 길이가 4라면 4개의 입력 글자 시퀀스로부터 4개의 출력 글자 시퀀스 예측. 즉 RNN의 time step은 4번\n",
        "# appl -> pple\n",
        "# appl (입력시퀀스, train_x), pple(예측해야하는 시퀀스, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0H6D-Bma6JL",
        "outputId": "d77b2739-6708-49dc-d969-88fb9c6bda6a"
      },
      "source": [
        "seq_length = 60\n",
        "n_samples = int(np.floor((len(text) - 1)/seq_length))\n",
        "print(f'문장 샘플의 수: {n_samples}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수: 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T8tzo2ZbjHd"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "  x_sample = text[i * seq_length: (i+1)*seq_length]\n",
        "  x_encoded = [char_to_index[c] for c in x_sample]\n",
        "  train_x.append(x_encoded)\n",
        "\n",
        "  y_sample = text[i*seq_length + 1: (i+1) * seq_length + 1]\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmqfJX-5cQLy",
        "outputId": "859c6f5d-65a4-4311-9ec3-659d13285428"
      },
      "source": [
        "print(train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f1xnoiacfQY",
        "outputId": "74b71584-1b42-41fa-cf75-d0169cf48db2"
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdasYFvbchyJ",
        "outputId": "85a627e0-b8fa-403b-f577-04a81dacaf9c"
      },
      "source": [
        "print(train_x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGfqayINclia",
        "outputId": "4ec6eb6b-9f91-4fdf-e5e2-cff97e0567cb"
      },
      "source": [
        "print(train_y[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL8j_8atcnyo"
      },
      "source": [
        "# x와 y에 대해 원-핫 인코딩 수행. 입력시퀀스에 대해 워드 임베딩 하지 않습니다 -> embedding layer 사용 X\n",
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECfSXxMrh_ln",
        "outputId": "bde64398-e4ad-40b2-8e8e-579f2a3421b1"
      },
      "source": [
        "print(f'train_x의 크기 (shape): {train_x.shape}')\n",
        "print(f'train_y의 크기 (shape): {train_y.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x의 크기 (shape): (2658, 60, 56)\n",
            "train_y의 크기 (shape): (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy9qa8hjiUhV",
        "outputId": "80ce0de1-f52a-41da-be04-9578cafdd84e"
      },
      "source": [
        "print(train_x[:3])\n",
        "print(train_y[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vZxKO5vilV4"
      },
      "source": [
        "샘플의 수가 2658, 입력시퀀스의 길이(input_length) 60, 각 벡터의 차원(input_dim) 56의 의미 원-핫 벡터의 차원은 글자 집합의 크기인 56"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-EsWP9YizH4"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKDloMobiXbi"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUvK0X5Di_bp"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape = (None, train_x.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn80RbiyjBhO",
        "outputId": "c3e430f0-a5ed-4a3d-d0c6-cadd6525a7cd"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=80, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 [==============================] - 10s 12ms/step - loss: 3.0600 - accuracy: 0.1844\n",
            "Epoch 2/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.7233 - accuracy: 0.2512\n",
            "Epoch 3/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.4106 - accuracy: 0.3256\n",
            "Epoch 4/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2848 - accuracy: 0.3520\n",
            "Epoch 5/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.1819 - accuracy: 0.3776\n",
            "Epoch 6/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.1113 - accuracy: 0.3944\n",
            "Epoch 7/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.0456 - accuracy: 0.4115\n",
            "Epoch 8/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.9954 - accuracy: 0.4232\n",
            "Epoch 9/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.9434 - accuracy: 0.4368\n",
            "Epoch 10/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.8992 - accuracy: 0.4490\n",
            "Epoch 11/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.8585 - accuracy: 0.4595\n",
            "Epoch 12/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.8203 - accuracy: 0.4710\n",
            "Epoch 13/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7839 - accuracy: 0.4811\n",
            "Epoch 14/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.7516 - accuracy: 0.4898\n",
            "Epoch 15/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7199 - accuracy: 0.4980\n",
            "Epoch 16/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6886 - accuracy: 0.5066\n",
            "Epoch 17/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6594 - accuracy: 0.5149\n",
            "Epoch 18/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6333 - accuracy: 0.5208\n",
            "Epoch 19/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6032 - accuracy: 0.5292\n",
            "Epoch 20/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5765 - accuracy: 0.5353\n",
            "Epoch 21/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5473 - accuracy: 0.5433\n",
            "Epoch 22/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5252 - accuracy: 0.5497\n",
            "Epoch 23/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4982 - accuracy: 0.5572\n",
            "Epoch 24/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4739 - accuracy: 0.5634\n",
            "Epoch 25/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4512 - accuracy: 0.5698\n",
            "Epoch 26/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4254 - accuracy: 0.5768\n",
            "Epoch 27/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3992 - accuracy: 0.5848\n",
            "Epoch 28/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3756 - accuracy: 0.5922\n",
            "Epoch 29/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3530 - accuracy: 0.5985\n",
            "Epoch 30/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3300 - accuracy: 0.6050\n",
            "Epoch 31/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3087 - accuracy: 0.6105\n",
            "Epoch 32/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2842 - accuracy: 0.6186\n",
            "Epoch 33/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2637 - accuracy: 0.6228\n",
            "Epoch 34/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2415 - accuracy: 0.6289\n",
            "Epoch 35/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2155 - accuracy: 0.6381\n",
            "Epoch 36/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1942 - accuracy: 0.6437\n",
            "Epoch 37/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1727 - accuracy: 0.6499\n",
            "Epoch 38/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1456 - accuracy: 0.6571\n",
            "Epoch 39/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1299 - accuracy: 0.6615\n",
            "Epoch 40/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1023 - accuracy: 0.6693\n",
            "Epoch 41/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0768 - accuracy: 0.6782\n",
            "Epoch 42/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0566 - accuracy: 0.6833\n",
            "Epoch 43/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0300 - accuracy: 0.6920\n",
            "Epoch 44/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0131 - accuracy: 0.6962\n",
            "Epoch 45/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9907 - accuracy: 0.7036\n",
            "Epoch 46/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9675 - accuracy: 0.7101\n",
            "Epoch 47/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9381 - accuracy: 0.7196\n",
            "Epoch 48/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9180 - accuracy: 0.7249\n",
            "Epoch 49/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8950 - accuracy: 0.7324\n",
            "Epoch 50/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8724 - accuracy: 0.7396\n",
            "Epoch 51/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8490 - accuracy: 0.7472\n",
            "Epoch 52/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8251 - accuracy: 0.7558\n",
            "Epoch 53/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8030 - accuracy: 0.7613\n",
            "Epoch 54/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7767 - accuracy: 0.7698\n",
            "Epoch 55/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.7565 - accuracy: 0.7767\n",
            "Epoch 56/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7459 - accuracy: 0.7792\n",
            "Epoch 57/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.7147 - accuracy: 0.7903\n",
            "Epoch 58/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6966 - accuracy: 0.7953\n",
            "Epoch 59/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6678 - accuracy: 0.8053\n",
            "Epoch 60/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.8096\n",
            "Epoch 61/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6294 - accuracy: 0.8175\n",
            "Epoch 62/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6079 - accuracy: 0.8240\n",
            "Epoch 63/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6001 - accuracy: 0.8257\n",
            "Epoch 64/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5825 - accuracy: 0.8306\n",
            "Epoch 65/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.5601 - accuracy: 0.8394\n",
            "Epoch 66/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5460 - accuracy: 0.8437\n",
            "Epoch 67/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.5292 - accuracy: 0.8484\n",
            "Epoch 68/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.5044 - accuracy: 0.8576\n",
            "Epoch 69/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.4931 - accuracy: 0.8607\n",
            "Epoch 70/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4694 - accuracy: 0.8695\n",
            "Epoch 71/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.4605 - accuracy: 0.8710\n",
            "Epoch 72/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4383 - accuracy: 0.8793\n",
            "Epoch 73/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4222 - accuracy: 0.8848\n",
            "Epoch 74/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.4107 - accuracy: 0.8873\n",
            "Epoch 75/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3956 - accuracy: 0.8929\n",
            "Epoch 76/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3944 - accuracy: 0.8916\n",
            "Epoch 77/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3718 - accuracy: 0.9000\n",
            "Epoch 78/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3553 - accuracy: 0.9055\n",
            "Epoch 79/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3433 - accuracy: 0.9092\n",
            "Epoch 80/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3249 - accuracy: 0.9154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dfa62ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjM-ollTjwb6"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]] # 랜덤 익덱스로부터 글자 생성\n",
        "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
        "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LbgMJwNmoL6a",
        "outputId": "d0d9464f-3d65-4774-96c7-bd00443b5bf4"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42 번 글자 m 로 예측을 시작!\n",
            "may copy it, give it away or re-use it under the terms of the project gutenberg literary archive fou"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'may copy it, give it away or re-use it under the terms of the project gutenberg literary archive foun'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "x-fyDtMLoO-9",
        "outputId": "fdc9a0f1-1c98-4603-c1d5-47c2814d42ec"
      },
      "source": [
        "sentence_generation(model, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 번 글자 # 로 예측을 시작!\n",
            "# and the queen said to alice. come on! even befor"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# and the queen said to alice. come on! even before'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Nc8GPQhyo2TI",
        "outputId": "e0cf9637-7bf4-4ee3-8a9e-97b6cd25bb3e"
      },
      "source": [
        "sentence_generation(model, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25 번 글자 ; 로 예측을 시작!\n",
            "; they all returned from him t"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'; they all returned from him to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOJrA4RQtdYh"
      },
      "source": [
        "## 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-tPkXntiIJ"
      },
      "source": [
        "다 대 일(many to one)구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성하기\n",
        "\n",
        "## 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVegkDwzo57D"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgEWH0FptwT8"
      },
      "source": [
        "text='''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwNdbaaGt7xO",
        "outputId": "d8e61513-d209-4def-ba1f-dc677f821fa4"
      },
      "source": [
        "tokens = text.split() # '\\n 제거'\n",
        "text = ' '.join(tokens)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6fq0pGuUa2",
        "outputId": "d100de77-cb76-406a-de20-f7d9137d3bfd"
      },
      "source": [
        "char_vocab = sorted(list(set(text)))\n",
        "print(char_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOfIQGR-ufJY",
        "outputId": "88cc0b04-d76b-4ec3-8b97-4f7326025cf6"
      },
      "source": [
        "vocab_size = len(char_vocab)\n",
        "print(f'글자 집합의 크기: {vocab_size}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4i_7ClCus2W",
        "outputId": "819c6996-5711-4da5-aa2b-0c7d4283ec58"
      },
      "source": [
        "char_to_index = dict((c,i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbkgDVYDvB_w"
      },
      "source": [
        " example 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측\n",
        "- stude -> n\n",
        "- tuden -> t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3cysdoau3il",
        "outputId": "b0c7b3ff-2634-4503-e552-577de7e5678a"
      },
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(text)):\n",
        "  seq = text[i-length:i]\n",
        "  sequences.append(seq)\n",
        "\n",
        "print('총 훈련 샘플의 수: %d' %len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 훈련 샘플의 수: 426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo_4rdNrvjs7",
        "outputId": "46f913f3-da20-4b5f-9ec2-427f3cbb8b11"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a', 'ith life as', 'th life as ', 'h life as a', ' life as a ', 'life as a p', 'ife as a pr', 'fe as a pro', 'e as a prog', ' as a progr', 'as a progra', 's a program', ' a programm', 'a programme', ' programmer', 'programmer,', 'rogrammer, ', 'ogrammer, I', 'grammer, I ', 'rammer, I l', 'ammer, I li', 'mmer, I lik', 'mer, I like', 'er, I like ', 'r, I like t', ', I like to', ' I like to ', 'I like to c', ' like to co', 'like to con', 'ike to cont', 'ke to conte', 'e to contem', ' to contemp', 'to contempl', 'o contempla', ' contemplat', 'contemplate', 'ontemplate ', 'ntemplate b', 'template be', 'emplate bee', 'mplate beer', 'plate beer.', 'late beer. ', 'ate beer. B', 'te beer. Bu', 'e beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sta', 'when I star', 'hen I start', 'en I start ', 'n I start t', ' I start to', 'I start to ', ' start to d', 'start to da', 'tart to day', 'art to dayd', 'rt to daydr', 't to daydre', ' to daydrea', 'to daydream', 'o daydream,', ' daydream, ', 'daydream, M', 'aydream, My', 'ydream, My ', 'dream, My m', 'ream, My mi', 'eam, My min', 'am, My mind', 'm, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. D', 'to wine. Do', 'o wine. Do ', ' wine. Do I', 'wine. Do I ', 'ine. Do I l', 'ne. Do I lo', 'e. Do I lov', '. Do I love', ' Do I love ', 'Do I love w', 'o I love wi', ' I love win', 'I love wine', ' love wine ', 'love wine m', 'ove wine mo', 've wine mor', 'e wine more', ' wine more ', 'wine more t', 'ine more th', 'ne more tha', 'e more than', ' more than ', 'more than b', 'ore than be', 're than bee', 'e than beer', ' than beer?', 'than beer? ', 'han beer? I', 'an beer? I ', 'n beer? I l', ' beer? I li', 'beer? I lik', 'eer? I like', 'er? I like ', 'r? I like t', '? I like to', ' I like to ', 'I like to u', ' like to us', 'like to use', 'ike to use ', 'ke to use w', 'e to use wo', ' to use wor', 'to use word', 'o use words', ' use words ', 'use words a', 'se words ab', 'e words abo', ' words abou', 'words about', 'ords about ', 'rds about b', 'ds about be', 's about bee', ' about beer', 'about beer.', 'bout beer. ', 'out beer. B', 'ut beer. Bu', 't beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sto', 'when I stop', 'hen I stop ', 'en I stop m', 'n I stop my', ' I stop my ', 'I stop my t', ' stop my ta', 'stop my tal', 'top my talk', 'op my talki', 'p my talkin', ' my talking', 'my talking,', 'y talking, ', ' talking, M', 'talking, My', 'alking, My ', 'lking, My m', 'king, My mi', 'ing, My min', 'ng, My mind', 'g, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. I', 'to wine. I ', 'o wine. I h', ' wine. I ha', 'wine. I hat', 'ine. I hate', 'ne. I hate ', 'e. I hate b', '. I hate bu', ' I hate bug', 'I hate bugs', ' hate bugs ', 'hate bugs a', 'ate bugs an', 'te bugs and', 'e bugs and ', ' bugs and e', 'bugs and er', 'ugs and err', 'gs and erro', 's and error', ' and errors', 'and errors.', 'nd errors. ', 'd errors. B', ' errors. Bu', 'errors. But', 'rrors. But ', 'rors. But I', 'ors. But I ', 'rs. But I j', 's. But I ju', '. But I jus', ' But I just', 'But I just ', 'ut I just t', 't I just th', ' I just thi', 'I just thin', ' just think', 'just think ', 'ust think b', 'st think ba', 't think bac', ' think back', 'think back ', 'hink back t', 'ink back to', 'nk back to ', 'k back to w', ' back to wi', 'back to win', 'ack to wine', 'ck to wine,', 'k to wine, ', ' to wine, A', 'to wine, An', 'o wine, And', ' wine, And ', 'wine, And I', \"ine, And I'\", \"ne, And I'm\", \"e, And I'm \", \", And I'm h\", \" And I'm ha\", \"And I'm hap\", \"nd I'm happ\", \"d I'm happy\", \" I'm happy \", \"I'm happy o\", \"'m happy on\", 'm happy onc', ' happy once', 'happy once ', 'appy once a', 'ppy once ag', 'py once aga', 'y once agai', ' once again', 'once again.', 'nce again. ', 'ce again. I', 'e again. I ', ' again. I l', 'again. I li', 'gain. I lik', 'ain. I like', 'in. I like ', 'n. I like t', '. I like to', ' I like to ', 'I like to h', ' like to ha', 'like to han', 'ike to hang', 'ke to hang ', 'e to hang o', ' to hang ou', 'to hang out', 'o hang out ', ' hang out w', 'hang out wi', 'ang out wit', 'ng out with', 'g out with ', ' out with p', 'out with pr', 'ut with pro', 't with prog', ' with progr', 'with progra', 'ith program', 'th programm', 'h programmi', ' programmin', 'programming', 'rogramming ', 'ogramming a', 'gramming an', 'ramming and', 'amming and ', 'mming and d', 'ming and de', 'ing and dee', 'ng and deep', 'g and deep ', ' and deep l', 'and deep le', 'nd deep lea', 'd deep lear', ' deep learn', 'deep learni', 'eep learnin', 'ep learning', 'p learning.', ' learning. ', 'learning. B', 'earning. Bu', 'arning. But', 'rning. But ', 'ning. But w', 'ing. But wh', 'ng. But whe', 'g. But when', '. But when ', ' But when l', 'But when le', 'ut when lef', 't when left', ' when left ', 'when left a', 'hen left al', 'en left alo', 'n left alon', ' left alone', 'left alone,', 'eft alone, ', 'ft alone, M', 't alone, My', ' alone, My ', 'alone, My m', 'lone, My mi', 'one, My min', 'ne, My mind', 'e, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAtze9kdvq3w"
      },
      "source": [
        "x = []\n",
        "for line in sequences:\n",
        "  temp_x = [char_to_index[char] for char in line]\n",
        "  x.append(temp_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPsSieC4wGEj",
        "outputId": "0e8c3bcd-3691-4c5a-fe41-80b6956d7d89"
      },
      "source": [
        "for line in x[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18]\n",
            "[0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28]\n",
            "[16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]\n",
            "[14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0]\n",
            "[28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXCoXLt0wIMY"
      },
      "source": [
        "sequences = np.array(x)\n",
        "x = sequences[:, :-1]\n",
        "y = sequences[:,-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAoVxOcVwihj",
        "outputId": "4d92bfe5-d192-46e2-d8d1-6b3853dcd703"
      },
      "source": [
        "for line in x[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8  0 16 14 28  0 24 23  0 31]\n",
            "[ 0 16 14 28  0 24 23  0 31 18]\n",
            "[16 14 28  0 24 23  0 31 18 28]\n",
            "[14 28  0 24 23  0 31 18 28 17]\n",
            "[28  0 24 23  0 31 18 28 17  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXLYym4GwmZd",
        "outputId": "2bcf5ab0-2628-4a3b-9760-1649053cebca"
      },
      "source": [
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 28 17  0 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zppOALc_wpXR"
      },
      "source": [
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ij3EJqLw8jw"
      },
      "source": [
        "x = np.array(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZW8EQWdxFVY",
        "outputId": "a0b7980c-69d4-4149-a148-fcafd55c4749"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 1. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE0Oaw28xGAz"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbQ4lX0CxPkM",
        "outputId": "c2a3bc9c-d9ec-473b-baf4-610506ff3969"
      },
      "source": [
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2kt0H96xRe_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjWyfQCzyycm"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (x.shape[1], x.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ymtDRoHzDsQ",
        "outputId": "00a51bb4-3bfd-498c-8049-10738612624e"
      },
      "source": [
        "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x,y, epochs=100, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 3.4488 - accuracy: 0.1385\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.1928 - accuracy: 0.1972\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.0066 - accuracy: 0.1972\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9675 - accuracy: 0.1972\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9497 - accuracy: 0.1972\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9180 - accuracy: 0.1972\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8921 - accuracy: 0.1972\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8703 - accuracy: 0.2230\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8413 - accuracy: 0.1972\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8080 - accuracy: 0.2089\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.7546 - accuracy: 0.1995\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.7103 - accuracy: 0.2418\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.6228 - accuracy: 0.2371\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.5676 - accuracy: 0.2441\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4992 - accuracy: 0.2911\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.3906 - accuracy: 0.3099\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.3094 - accuracy: 0.3545\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.2680 - accuracy: 0.3146\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.1798 - accuracy: 0.3850\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0962 - accuracy: 0.3803\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.0153 - accuracy: 0.4131\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.9448 - accuracy: 0.4695\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8726 - accuracy: 0.4953\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.8222 - accuracy: 0.5094\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.7555 - accuracy: 0.5023\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.6980 - accuracy: 0.5376\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6345 - accuracy: 0.5563\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5952 - accuracy: 0.5587\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5726 - accuracy: 0.5845\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4893 - accuracy: 0.5939\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4123 - accuracy: 0.6033\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.3956 - accuracy: 0.6268\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2974 - accuracy: 0.6549\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2285 - accuracy: 0.6925\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1951 - accuracy: 0.6878\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1190 - accuracy: 0.7300\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0634 - accuracy: 0.7535\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0036 - accuracy: 0.7512\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9704 - accuracy: 0.7582\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9186 - accuracy: 0.7817\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.8052\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.8058 - accuracy: 0.8263\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.8427\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.8451\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.8638\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.8521\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.8615\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.8709\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.8991\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.9131\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.9131\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.9366\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.9460\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.9531\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.9507\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.9507\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.9577\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.9648\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.9671\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9695\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2677 - accuracy: 0.9789\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.9671\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.9648\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9695\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9789\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9695\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9765\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9695\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9742\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9718\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9789\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9812\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9742\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9742\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9742\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.9789\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9812\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9765\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9859\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9836\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9742\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9765\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9789\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9789\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.9789\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9718\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9765\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9742\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9671\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9812\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9812\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9812\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9789\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9836\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9765\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9836\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9836\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9836\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9812\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2df2091cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLHl08tTzSCG"
      },
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n): \n",
        "  # 모델, 인덱스 정보, 문장의 길이, 초기 시퀀스, 반복 횟수\n",
        "\n",
        "  init_text = seed_text #문장 생성에 사용할 초기 시퀀스\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = [char_to_index[char] for char in seed_text]\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') #데이터에 대한 패딩\n",
        "    encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "    result = model.predict_classes(encoded, verbose=0)\n",
        "    #입력한 x(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 글자)를 result에 저장\n",
        "\n",
        "    for char, index in char_to_index.items(): #만약 예측한 글자와 인덱스와 동일한 글자가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "    \n",
        "    seed_text = seed_text + char # 현재 시퀀스 + 예측 글자를 현재 시퀀스에 변경\n",
        "    sentence = sentence + char\n",
        "\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PfZJTW1JzC",
        "outputId": "c3fb1d6a-74c4-4487-b747-e56b313fb0a4"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to use words about beer. But when I start to daydream, My mind turn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E5inu-1ckP",
        "outputId": "8a61e24e-503f-4356-bc3a-0faf2834297b"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'Do I love wine', 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Do I love wine more than beer? I like to use words about beer. But when I start to daydream, My mind turns straigh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhbGxF3iXQvI"
      },
      "source": [
        "## 네이버 쇼핑 리뷰 감성 분석\n",
        "- 총 200,000개 리뷰로 구성\n",
        "- 평점이 5점 만점에 1,2,4,5인 리뷰들로 구성\n",
        "- 평점이 4,5인 리뷰들에 긍정1, 부정0\n",
        "- 감정분류 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeLoGXTp1j0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dc50e4-f4a4-494b-c299-8f186c3bb339"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le1R_o56XPnL",
        "outputId": "69d50a41-0b7f-48c3-f4c7-d002cd91ae16"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPwVjDKIXsl8",
        "outputId": "3359f299-e5d6-48d5-f1d9-55dd73418e14"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/                                    LICENSE\n",
            "install_mecab-ko_on_colab190912.sh         README.md\n",
            "install_mecab-ko_on_colab_light_210108.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxzKRRF1XtAL",
        "outputId": "3cad65dd-f585-4ec1-957c-96d9579cfe62"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.4MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 54.0MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Installing collected packages: beautifulsoup4, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-17 05:08:45--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.2, 18.205.93.1, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=VxU26vc9FV3JNOomuRLBhcbAMDs%3D&Expires=1623907534&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 05:08:45--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=VxU26vc9FV3JNOomuRLBhcbAMDs%3D&Expires=1623907534&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.47.60\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.47.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-06-17 05:08:45 (25.0 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-17 05:10:06--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.0, 18.205.93.1, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2B7bEmbHCl21WZ2PCLLhxUw7Khz4%3D&Expires=1623907603&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 05:10:06--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2B7bEmbHCl21WZ2PCLLhxUw7Khz4%3D&Expires=1623907603&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.74.188\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.74.188|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   101MB/s    in 0.5s    \n",
            "\n",
            "2021-06-17 05:10:07 (101 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvfS2rrbYuGT"
      },
      "source": [
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOrH5-zyXwEH",
        "outputId": "418b1fa7-9efd-41c5-ecdf-7b5b28a8253b"
      },
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs('와 이런 것도 상품이라고 차라리 내가 만드는게 나을까?ㅎㅎ'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['와', '이런', '것', '도', '상품', '이', '라고', '차라리', '내', '가', '만드', '는', '게', '나', '을까', '?', 'ㅎㅎ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vr3CGj7Yrzr",
        "outputId": "dde30ad5-e2b9-4a3f-f47a-dc47ab29c74a"
      },
      "source": [
        "print(mecab.morphs('밥먹고 공부하려니 졸립고 나른하군 ㅠㅠ'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['밥', '먹', '고', '공부', '하', '려니', '졸립', '고', '나른', '하군', 'ㅠㅠ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMyCTEURZSEL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IVsG-C8aoCv",
        "outputId": "bcdb9585-f87e-4b9b-a8d1-4e5e6a4184f6"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7f7678e474d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1w60jucaqt6"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['rating', 'reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSA8HLpka0qj",
        "outputId": "83bbf275-c622-4ea8-e04c-9c225bf946c4"
      },
      "source": [
        "print('전체 리뷰 갯수:', len(total_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 리뷰 갯수: 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5Ikis_Eua4k8",
        "outputId": "e345a921-1b75-4866-cb19-9082fad245f2"
      },
      "source": [
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                            reviews\n",
              "0       5                                            배공빠르고 굿\n",
              "1       2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2       5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3       2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4       5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B_btxDKbCby"
      },
      "source": [
        "## 훈련 데이터와 테스트 데이터를 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pkb_xMaLa6TA",
        "outputId": "bc92559c-387e-4104-e0f7-7275b5dd6942"
      },
      "source": [
        "total_data['label'] = np.select([total_data.rating > 3], [1], default=0)\n",
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                            reviews  label\n",
              "0       5                                            배공빠르고 굿      1\n",
              "1       2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
              "2       5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
              "3       2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
              "4       5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49IOwhyebQUy",
        "outputId": "94822659-83e4-405f-cea9-d396202e3533"
      },
      "source": [
        "total_data['rating'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 199908, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCRGp8JCbnpQ",
        "outputId": "bdd6adec-d182-4f95-da8e-6812fb73d33d"
      },
      "source": [
        "total_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "print('총 샘플의 수:',len(total_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 수: 199908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jji8Lwacbyl0",
        "outputId": "b075b8ab-49aa-43f9-e072-7d1cdc2b2a86"
      },
      "source": [
        "#Null값 유무\n",
        "print(total_data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCJagxr4cFbE",
        "outputId": "418b682c-b66b-41cd-8f83-f281187e2d89"
      },
      "source": [
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state=42)\n",
        "print('훈련용 리뷰의 갯수: ',len(train_data))\n",
        "print('테스트용 리뷰의 갯수: ',len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰의 갯수:  149931\n",
            "테스트용 리뷰의 갯수:  49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "X3arPE14cXFf",
        "outputId": "5f6593e5-d4cc-4a63-9f51-f125ed0f7417"
      },
      "source": [
        "train_data['label'].value_counts().plot(kind = 'bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7673d0d150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ1MWLFlcgHb",
        "outputId": "d15ebb74-39c0-45c9-fd79-bc0b58124396"
      },
      "source": [
        "print(train_data.groupby('label').size().reset_index(name='count'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  count\n",
            "0      0  74918\n",
            "1      1  75013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClxWZpDUcwTf"
      },
      "source": [
        "### 데이터 정제하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OXWvJffc05U"
      },
      "source": [
        "정규표현식을 사용하여 한글을 제외하고 모두제거\n",
        "\n",
        "빈 샘플이 생겼는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DslthHZ3cqg9",
        "outputId": "30d12058-3f7f-4259-9ff9-c84c5f538f7f"
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace('[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]', '')\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rating     0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOfo-UxWdWKt",
        "outputId": "396d703a-999c-47f1-904f-48568d273100"
      },
      "source": [
        "test_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "test_data['reviews'] = test_data['reviews'].str.replace('[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]', '')\n",
        "test_data['reviews'].replace('', np.nan, inplace = True)\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘픙의 갯수:',len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전처리 후 테스트용 샘픙의 갯수: 49977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wrH466Wd6Dj"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkLpbFxwd1Ic",
        "outputId": "5ec464aa-35ef-4edf-a060-86fddb348720"
      },
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs('이런 상품도 상품이라고 하하하'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이런', '상품', '도', '상품', '이', '라고', '하하하']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92F8ygOzd_yc"
      },
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiVwRbTleLmb",
        "outputId": "2774799d-8f1f-4ab5-f58a-f53ccd6517fd"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT2325ceisU"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoiZ1vTAe2Sb"
      },
      "source": [
        "### 단어와 길이 분포 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKCET06sevxc"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8bFK5nf75M",
        "outputId": "e2ebcb0f-aae0-45c4-895a-4448f724aa3a"
      },
      "source": [
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('네요', 31799), ('는데', 20295), ('안', 19718), ('어요', 14849), ('있', 13200), ('너무', 13058), ('했', 11783), ('좋', 9812), ('배송', 9677), ('같', 8997), ('구매', 8876), ('어', 8869), ('거', 8854), ('없', 8670), ('아요', 8642), ('습니다', 8436), ('그냥', 8355), ('되', 8345), ('잘', 8029), ('않', 7984)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4ks_h5-gP3n",
        "outputId": "55d1d23a-90cf-4980-978c-2b1a79c0663e"
      },
      "source": [
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('좋', 39488), ('아요', 21184), ('네요', 19895), ('어요', 18686), ('잘', 18602), ('구매', 16171), ('습니다', 13320), ('있', 12391), ('배송', 12275), ('는데', 11670), ('했', 9818), ('합니다', 9801), ('먹', 9635), ('재', 9273), ('너무', 8397), ('같', 7868), ('만족', 7261), ('거', 6482), ('어', 6294), ('쓰', 6292)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "ZtjqpLYlgbq6",
        "outputId": "d7a354aa-669c-4286-c493-81bc46c39699"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
        "text_len = train_data[train_data['label']== 1]['tokenized'].map(lambda x: len(x))\n",
        "ax1.hist(text_len, color = 'red')\n",
        "ax1.set_title('Positive Reviews')\n",
        "ax1.set_xlabel('length of samples')\n",
        "ax1.set_ylabel('number of samples')\n",
        "print('긍정 리뷰의 평균 길이', np.mean(text_len))\n",
        "\n",
        "text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "ax2.hist(text_len, color = 'blue')\n",
        "ax2.set_title('Negative Reviews')\n",
        "ax2.set_title('Words in texts')\n",
        "ax2.set_xlabel('length of samples')\n",
        "ax2.set_ylabel('number of samples')\n",
        "print('부정 리뷰의 평균 길이', np.mean(text_len))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "긍정 리뷰의 평균 길이 13.587751456414221\n",
            "부정 리뷰의 평균 길이 17.029512266744973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Tcdm5uhib8"
      },
      "source": [
        "x_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "x_test = test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb7iG942igbs"
      },
      "source": [
        "정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCqw3emoifvf"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHCMdX83ieuW",
        "outputId": "64250c33-4b03-4245-9501-ccd3dbfddc49"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(t.word_index)\n",
        "rare_cnt = 0\n",
        "total_freq = 0\n",
        "rare_freq = 0\n",
        "\n",
        "#단어와 빈도수의 쌍을 key와 value로 받는다.\n",
        "for key, value in t.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  if (value < threshold):\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기:', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀단어의 수: %s' %(threshold-1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어의 비율: ',(rare_cnt / total_cnt)* 100)\n",
        "print('전체 등장 빈도에서 희귀단어 등장 빈도 비율: ',(rare_freq/total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기: 39998\n",
            "등장 빈도가 1번 이하인 희귀단어의 수: 18213\n",
            "단어 집합에서 희귀 단어의 비율:  45.53477673883694\n",
            "전체 등장 빈도에서 희귀단어 등장 빈도 비율:  0.7935688376196857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlvQ_JmgpPKz"
      },
      "source": [
        "더블클릭 또는 Enter 키를 눌러 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2boFpTXJjsbZ",
        "outputId": "68f5826c-81aa-4841-eb5d-b1dae07dded8"
      },
      "source": [
        "#전체 단어 갯수 중 빈도수 2이이항린 단어 갯수는 제거\n",
        "#0번 패딩 토큰과 1번 OOV토큰을 고려해서 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기:',vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기: 21787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-uOegMFpnkd",
        "outputId": "7b3a30f7-f3c8-47f2-ed6c-67d97a40e16c"
      },
      "source": [
        "original_vocab_size = vocab_size + rare_cnt - 2\n",
        "print('원래 vocab size', original_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원래 vocab size 39998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLVS8tgBp1hB"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvKXzWFLqX-F",
        "outputId": "c02ac5aa-8d08-47a6-f17b-903fd09f2656"
      },
      "source": [
        "print(x_train[:3])\n",
        "print(x_test[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67, 2060, 299, 14259, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]\n",
            "[[14, 704, 767, 116, 186, 252, 12], [339, 3904, 62, 3816, 1651], [11, 69, 2, 49, 164, 3, 27, 15, 6, 513, 289, 17, 92, 110, 564, 59, 7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "_BlvzamxsrBT",
        "outputId": "3b7bc719-5637-4f42-c492-9c4132dab095"
      },
      "source": [
        "print('리뷰의 최대 길이 :', max(len(l) for l in x_train))\n",
        "print('리뷰의 평균 길이 :', sum(map(len, x_train))/len(x_train))\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 85\n",
            "리뷰의 평균 길이 : 15.307541469075774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecz1G7Cnssjh"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if (len(s) <= max_len):\n",
        "      cnt += 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율 : %s' %(max_len, (cnt/len(nested_list))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXfNtlpGtC_P",
        "outputId": "417ce308-b87e-48af-80ed-828c23e38d0b"
      },
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율 : 99.99933302652553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFjq58qBtH0F"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TccxLFxDtP_M",
        "outputId": "1faf7eb4-fab2-485f-97f7-0ca90526c1f4"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149931, 80)\n",
            "(49977, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFWeoe9JtceG"
      },
      "source": [
        "### GRU모델로 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlFDOI2-tUSJ"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSAf7NLbtvRh"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc8xka7wuHx8"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode = 'max', verbose=1, save_best_only= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyOpBg3KucuI",
        "outputId": "11e37000-dd0d-439c-e9cd-280f831cf718"
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train, epochs=30, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 73s 32ms/step - loss: 0.2750 - acc: 0.8953 - val_loss: 0.2224 - val_acc: 0.9201\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.92010, saving model to best_model.h5\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 60s 30ms/step - loss: 0.1961 - acc: 0.9312 - val_loss: 0.2277 - val_acc: 0.9168\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.92010\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 59s 30ms/step - loss: 0.1649 - acc: 0.9429 - val_loss: 0.2252 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92010\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 59s 30ms/step - loss: 0.1375 - acc: 0.9526 - val_loss: 0.2503 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92010\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 59s 30ms/step - loss: 0.1125 - acc: 0.9608 - val_loss: 0.2782 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92010\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PA-PpCYyLie",
        "outputId": "92d8f4a7-cc56-4f3b-b4d9-c949e98d27d5"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print('\\n 테스트 정확도 : %.4f' % (loaded_model.evaluate(x_test,y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 7s 4ms/step - loss: 0.2288 - acc: 0.9182\n",
            "\n",
            " 테스트 정확도 : 0.9182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX2AbNlfxFt1"
      },
      "source": [
        "### 리뷰 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPFTPN5ou015"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = mecab.morphs(new_sentence)\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
        "\n",
        "  score = float(loaded_model.predict(pad_new))\n",
        "\n",
        "  if score > 0.5 :\n",
        "    print('{:.2f}%학률로 긍정 리뷰입니다.'.format(score*100))\n",
        "  else:\n",
        "    print('{:.2f}%확률로 부정 리뷰입니다.'.format((1-score)*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-ZahjIpyrJ_",
        "outputId": "830bb4bc-ac7a-48ce-8368-4e93cc52c4b2"
      },
      "source": [
        "sentiment_predict('이 상품 진짜 좋아요.. 저는 강추 대박')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.25%학률로 긍정 리뷰입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-SKBoyXyu7l",
        "outputId": "4668d894-bee8-4ed5-e128-92bdec0262f1"
      },
      "source": [
        "sentiment_predict('진짜 배송 늦고 개별로 개짜증')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.75%확률로 부정 리뷰입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlPxM302y20Q",
        "outputId": "9fd8b052-0535-4327-c6ca-90d53ac2e17b"
      },
      "source": [
        "sentiment_predict('그냥 그래요')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.68%확률로 부정 리뷰입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gN4Pnh1y5cp",
        "outputId": "15d2d1d7-ddd4-46a6-818d-f7e7db20b1d8"
      },
      "source": [
        "sentiment_predict('너무 짱이에요')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.09%학률로 긍정 리뷰입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWfwOS7t4cWr"
      },
      "source": [
        "### 글자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "M7_cFalJy8uy",
        "outputId": "57b4eb95-cbc2-4d77-8783-d4d04b9e7909"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/dataset/fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra','cc'], sep = '\\t')\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109561</th>\n",
              "      <td>Why are you being so negative?</td>\n",
              "      <td>Pourquoi es-tu si négative ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171919</th>\n",
              "      <td>Something happened here, but I don't know what.</td>\n",
              "      <td>Quelque chose a eu lieu ici, mais j'ignore quoi.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55675</th>\n",
              "      <td>I'm trying to be happy.</td>\n",
              "      <td>J'essaye d'être heureux.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88705</th>\n",
              "      <td>You did that the wrong way.</td>\n",
              "      <td>Vous avez fait ça de la mauvaise façon.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95824</th>\n",
              "      <td>You are curious, aren't you?</td>\n",
              "      <td>Vous êtes curieuses, hein ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    eng  ...                                                 cc\n",
              "109561                   Why are you being so negative?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "171919  Something happened here, but I don't know what.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "55675                           I'm trying to be happy.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "88705                       You did that the wrong way.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "95824                      You are curious, aren't you?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMOAjpE35W_o"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0aYz7yNh6Aba",
        "outputId": "f713802d-6a85-491f-c44c-75e2eed49d91"
      },
      "source": [
        "lines = lines[['eng','fra']][:50000]\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46670</th>\n",
              "      <td>Have yourself a drink.</td>\n",
              "      <td>Sers-toi une boisson !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37791</th>\n",
              "      <td>Turn off the lights.</td>\n",
              "      <td>Éteins les phares !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46406</th>\n",
              "      <td>Don't forget the milk.</td>\n",
              "      <td>N'oublie pas le lait !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21380</th>\n",
              "      <td>You need to stop.</td>\n",
              "      <td>Tu dois cesser.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30123</th>\n",
              "      <td>May I open the box?</td>\n",
              "      <td>Puis-je ouvrir la boîte ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                        fra\n",
              "46670  Have yourself a drink.     Sers-toi une boisson !\n",
              "37791    Turn off the lights.        Éteins les phares !\n",
              "46406  Don't forget the milk.     N'oublie pas le lait !\n",
              "21380       You need to stop.            Tu dois cesser.\n",
              "30123     May I open the box?  Puis-je ouvrir la boîte ?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "-2QJ-ROP6Wrz",
        "outputId": "91d20cff-7692-48ca-8325-0f1c88055d08"
      },
      "source": [
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "lines.fra = lines.fra.apply(lambda x: '\\t' + x + '\\n')\n",
        "print('전체 샘플의 수:',len(lines))\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수: 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28426</th>\n",
              "      <td>I can confirm that.</td>\n",
              "      <td>\\tJe peux le confirmer.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6469</th>\n",
              "      <td>Can you pitch?</td>\n",
              "      <td>\\tSais-tu donner le ton ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15574</th>\n",
              "      <td>Tom fought back.</td>\n",
              "      <td>\\tTom a riposté.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8031</th>\n",
              "      <td>Read this now.</td>\n",
              "      <td>\\tLis ça maintenant !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15494</th>\n",
              "      <td>This is special.</td>\n",
              "      <td>\\tC'est spécial.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       eng                          fra\n",
              "28426  I can confirm that.    \\tJe peux le confirmer.\\n\n",
              "6469        Can you pitch?  \\tSais-tu donner le ton ?\\n\n",
              "15574     Tom fought back.           \\tTom a riposté.\\n\n",
              "8031        Read this now.      \\tLis ça maintenant !\\n\n",
              "15494     This is special.           \\tC'est spécial.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41UK0DTN68XH",
        "outputId": "1eae9d8b-2eee-4fc5-a9ce-6ada82ad11e0"
      },
      "source": [
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "input_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNVHa4D17Wzp",
        "outputId": "95a5f8a7-ba4f-4275-c381-528ecc40f3a7"
      },
      "source": [
        "fra_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "target_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 19, 5, 1, 31, 11],\n",
              " [10, 15, 5, 12, 16, 29, 2, 14, 11],\n",
              " [10, 26, 9, 8, 28, 2, 1, 31, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esTw48J77lnb",
        "outputId": "61176a61-fe77-4f31-9184-6af2ac2902cf"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장:',eng_vocab_size)\n",
        "print('프랑스어 단어장:', fra_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장: 52\n",
            "프랑스어 단어장: 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFSkdNGE7_Ln",
        "outputId": "a848415f-76e4-4bf2-bf83-a31a128aee69"
      },
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "print('영어 시퀀스의 최대 길이:', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이:', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이: 22\n",
            "프랑스어 시퀀스의 최대 길이: 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421UBo3H8Wzz",
        "outputId": "c1267958-3fc8-4bfa-88c4-3d7553b45a14"
      },
      "source": [
        "print('전체 샘플의 수: ',len(lines))\n",
        "print('영어 단어장의 크기:', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기:', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이: ', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이:', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수:  50000\n",
            "영어 단어장의 크기: 52\n",
            "프랑스어 단어장의 크기: 73\n",
            "영어 시퀀스의 최대 길이:  22\n",
            "프랑스어 시퀀스의 최대 길이: 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmWlVOsn8rUh"
      },
      "source": [
        "encoder_input=input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIXYbMzm9XQ2",
        "outputId": "252b36b8-ed87-41cf-f302-8d3958b2f494"
      },
      "source": [
        "print(decoder_input[:3])\n",
        "print(decoder_target[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[19, 5, 1, 31, 11], [15, 5, 12, 16, 29, 2, 14, 11], [26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8IEp2r69cHL",
        "outputId": "c150c73e-acb3-4649-cda6-84572a07c0d8"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape):', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기:', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기:', np.shape(decoder_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape): (50000, 22)\n",
            "프랑스어 입력데이터의 크기: (50000, 74)\n",
            "프랑스어 출력데이터의 크기: (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJS-iBTI-V5f",
        "outputId": "66145ace-7220-47fd-aa43-dc4f83117d64"
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBhjjoGq-ciR"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEGN3ir8-oFU",
        "outputId": "7cdbda96-d968-4c58-8fc4-f7de2c23ab22"
      },
      "source": [
        "decoder_target = to_categorical(decoder_target)\n",
        "print('영어 데이터의 크기: ',np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기: ',np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기: ',np.shape(decoder_target)) # 샘플의 수 x 샘플의 길이 x 단어장의 크기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기:  (50000, 22, 52)\n",
            "프랑스어 입력데이터의 크기:  (50000, 74, 73)\n",
            "프랑스어 출력데이터의 크기:  (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tu45ZlO-50T",
        "outputId": "2a1ce9d4-572d-4620-a661-422ac60f3cf6"
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습데이터의 크기: ',np.shape(encoder_input_train))\n",
        "print('프랑스어 학습 입력데이터의 크기: ',np.shape(decoder_input_train))\n",
        "print('프랑스어 학습 출력데이터의 크기: ',np.shape(decoder_target_train)) # 샘플의 수 x 샘플의 길이 x 단어장의 크기\n",
        "\n",
        "print('영어 테스트데이터의 크기: ',np.shape(encoder_input_test))\n",
        "print('프랑스어 테스트 입력데이터의 크기: ',np.shape(decoder_input_test))\n",
        "print('프랑스어 테스트 출력데이터의 크기: ',np.shape(decoder_target_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습데이터의 크기:  (47000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기:  (47000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기:  (47000, 74, 73)\n",
            "영어 테스트데이터의 크기:  (3000, 22, 52)\n",
            "프랑스어 테스트 입력데이터의 크기:  (3000, 74, 73)\n",
            "프랑스어 테스트 출력데이터의 크기:  (3000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPR1Sbd9_9zE"
      },
      "source": [
        "### 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyniBEWL_5-b"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODBLrCGJAJhP"
      },
      "source": [
        "# LSTM셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden state와 cell state전달해주자\n",
        "\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "# 입력 텐서를 생성\n",
        "encoder_lstm = LSTM(units= 256, return_state=True)\n",
        "# hidden state 256인 LSTM을 생성\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_output은 여기서는 불필요.\n",
        "encoder_states = [state_h, state_c]\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도로 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pDLPOSHA44f"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "decoder_lstm = LSTM(units=256, return_sequences= True, return_state=True)\n",
        "# hidden state size 256 디코더 LSTM 생성\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
        "# decoder output는 모든 timestep의 hidden state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81QS40COB3lf"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqSPtRY_CJV_",
        "outputId": "180f6dc8-dbc2-42aa-c35a-a596557b2e89"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 256), (None, 316416      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 256),  337920      input_6[0][0]                    \n",
            "                                                                 lstm_4[0][1]                     \n",
            "                                                                 lstm_4[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 73)     18761       lstm_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjHLfA9nCk8W",
        "outputId": "9fbcdbcf-fe88-4bf7-d212-e4df640d2b27"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 11s 23ms/step - loss: 0.9006 - val_loss: 0.8014\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.5618 - val_loss: 0.6577\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.4689 - val_loss: 0.5689\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.4140 - val_loss: 0.5148\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 8s 20ms/step - loss: 0.3771 - val_loss: 0.4909\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3495 - val_loss: 0.4580\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3281 - val_loss: 0.4335\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3107 - val_loss: 0.4210\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2966 - val_loss: 0.4086\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2848 - val_loss: 0.4000\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2746 - val_loss: 0.3877\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2657 - val_loss: 0.3830\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2577 - val_loss: 0.3759\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 8s 20ms/step - loss: 0.2506 - val_loss: 0.3819\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2440 - val_loss: 0.3689\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2381 - val_loss: 0.3683\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2326 - val_loss: 0.3625\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2273 - val_loss: 0.3684\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2225 - val_loss: 0.3622\n",
            "Epoch 20/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2179 - val_loss: 0.3623\n",
            "Epoch 21/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2136 - val_loss: 0.3644\n",
            "Epoch 22/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2094 - val_loss: 0.3600\n",
            "Epoch 23/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2056 - val_loss: 0.3593\n",
            "Epoch 24/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2019 - val_loss: 0.3582\n",
            "Epoch 25/30\n",
            "368/368 [==============================] - 8s 20ms/step - loss: 0.1984 - val_loss: 0.3583\n",
            "Epoch 26/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1950 - val_loss: 0.3616\n",
            "Epoch 27/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1918 - val_loss: 0.3656\n",
            "Epoch 28/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1887 - val_loss: 0.3663\n",
            "Epoch 29/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1858 - val_loss: 0.3710\n",
            "Epoch 30/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1829 - val_loss: 0.3677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76690126d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDQ5xj0tF_w_"
      },
      "source": [
        "### 모델 테스트\n",
        "\n",
        "훈련시에 학습해야할 타겟문장을 디코더 모델의 입력, 출력 시퀀스로 넣어주고, 디코더 모델이 타겟문장을 한꺼번에 출력하게 할 수 있습니다. 테스트 단계는 불가능!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0EW2odlGR40"
      },
      "source": [
        "테스트 단계에서 디코더 동작 순서\n",
        "- 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
        "- 토큰인 \\t를 디코더에 입력한다.\n",
        "- 이전 timestep의 출력층의 예측결과를 현재 timestep의 입력으로 한다.\n",
        "- 3을 반복하다가 토큰인 \\n가 예측되면 이를 중단한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EzFDZ9EDOb4",
        "outputId": "ca361424-64a9-45ea-b379-06be5e4ea705"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_outputs)\n",
        "encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, None, 52)]        0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                [(None, 256), (None, 256) 316416    \n",
            "=================================================================\n",
            "Total params: 316,416\n",
            "Trainable params: 316,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mV5Tu9gGyft"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oySyT-lgHTFK",
        "outputId": "590436bd-7348-46a8-e639-6922d5ef55db"
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs]+ decoder_state_inputs, outputs=[decoder_outputs]+ decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 256),  337920      input_6[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 73)     18761       lstm_5[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unu86KoNH01I"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BPS0XwEIF2h"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "  target_seq[0, 0, fra2idx['\\t']] =1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_fra_seq_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] =1\n",
        "\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "wAIReDv_JUwS",
        "outputId": "82298ce5-13cf-4a34-9a6e-cbd4a3c9159e"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input[seq_index: seq_index +1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.eng[seq_index])\n",
        "  print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "  print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence)-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-8f21e9678f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'입력 문장 :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-119-68c5eb2fe13f>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,1,1,73) (1,256) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU7jT-Q_JyHL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}